{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-08T08:09:25.473604Z",
     "start_time": "2025-11-08T08:09:22.417122Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import models\n",
    "\n",
    "data_path = r\"C:\\Users\\Arun\\Downloads\\images\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T08:09:25.489095Z",
     "start_time": "2025-11-08T08:09:25.478084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "augmentation = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n"
   ],
   "id": "ea5cc772071adf0e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T08:09:25.771350Z",
     "start_time": "2025-11-08T08:09:25.493580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "\n",
    "train_data = ImageFolder(root=data_path, transform=augmentation)\n",
    "training_len = int(len(train_data) * 0.8)\n",
    "validation_len = len(train_data) - training_len\n",
    "training_data,validation_data = random_split(train_data, [training_len, validation_len])\n",
    "train_data_loader = DataLoader(train_data, batch_size=960, shuffle=True,pin_memory=True)\n",
    "validation_data_loader = DataLoader(validation_data, batch_size=960, shuffle=True,pin_memory=True)"
   ],
   "id": "408fa54d1e2b846e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T08:09:25.786794Z",
     "start_time": "2025-11-08T08:09:25.776094Z"
    }
   },
   "cell_type": "code",
   "source": "num_classes = len(train_data.classes)",
   "id": "a898a9d52c86fa7e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T08:10:46.997876Z",
     "start_time": "2025-11-08T08:10:46.979422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision import models\n",
    "from torch import nn\n",
    "\n",
    "class cnn_model(nn.Module):\n",
    "    def __init__(self, num_classes=101):\n",
    "        super(cnn_model, self).__init__()\n",
    "        self.base = models.mobilenet_v3_small(\n",
    "            weights=models.MobileNet_V3_Small_Weights.IMAGENET1K_V1\n",
    "        )\n",
    "\n",
    "        for param in self.base.features.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        infeatures = self.base.classifier[0].in_features\n",
    "        self.base.classifier = nn.Sequential(\n",
    "            nn.Linear(infeatures, 512),\n",
    "            nn.Hardswish(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base(x)\n"
   ],
   "id": "a6cb62b063b49af8",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T08:10:47.765470Z",
     "start_time": "2025-11-08T08:10:47.628664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = cnn_model(num_classes=num_classes)\n",
    "model_loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer,\"min\",patience=2,factor=0.3)"
   ],
   "id": "a43a9e3db31d741e",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T08:10:48.167769Z",
     "start_time": "2025-11-08T08:10:48.153334Z"
    }
   },
   "cell_type": "code",
   "source": "from torch.amp import GradScaler,autocast",
   "id": "e4144e3102df8226",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T11:38:14.187549Z",
     "start_time": "2025-11-08T11:06:38.326426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 4\n",
    "scaler = GradScaler()\n",
    "torch.backends.cudnn.benchmark =  True\n",
    "model = model.to(device)\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    loop = tqdm(train_data_loader, desc=f\"Epoch [{epoch+1}/{epochs}]\", leave=False)\n",
    "\n",
    "    for image, label in loop:\n",
    "        image, label = image.to(device), label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast(device_type=\"cuda\",enabled=True,dtype= torch.float16):\n",
    "            output = model(image)\n",
    "            loss = model_loss(output, label)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += label.size(0)\n",
    "        correct += (predicted == label).sum().item()\n",
    "\n",
    "        loop.set_postfix(loss=loss.item(), acc=f\"{(correct/total)*100:.2f}%\")\n",
    "\n",
    "    train_loss = running_loss / len(train_data_loader)\n",
    "    train_acc = (correct / total) * 100\n",
    "\n",
    "    model.eval()\n",
    "    val_loss, vcorrect, vtotal = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for image, label in validation_data_loader:\n",
    "            image, label = image.to(device), label.to(device)\n",
    "            with autocast(device_type=\"cuda\"):\n",
    "                output = model(image)\n",
    "                loss = model_loss(output, label)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            vtotal += label.size(0)\n",
    "            vcorrect += (predicted == label).sum().item()\n",
    "\n",
    "    val_loss /= len(validation_data_loader)\n",
    "    val_acc = (vcorrect / vtotal) * 100\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | \"\n",
    "          f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
    "          f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "print(\"Training complete.\")"
   ],
   "id": "cefdfc7441d54863",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4] | Train Loss: 1.5405 | Train Acc: 59.64% | Val Loss: 1.3866 | Val Acc: 64.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/4] | Train Loss: 1.5279 | Train Acc: 59.91% | Val Loss: 1.3540 | Val Acc: 64.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/4] | Train Loss: 1.5092 | Train Acc: 60.36% | Val Loss: 1.3421 | Val Acc: 65.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/4] | Train Loss: 1.4871 | Train Acc: 60.78% | Val Loss: 1.2901 | Val Acc: 65.93%\n",
      "Training complete.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T11:42:30.539985Z",
     "start_time": "2025-11-08T11:42:30.387699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(model,open(\"cnn_model\",\"wb\"))"
   ],
   "id": "fab1ccf5a6b2036b",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b2fb8adc6ae3ac61"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
